{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNGG47UMUPABw7uf+bYZvEj"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Mount Notebook to Drive"],"metadata":{"id":"S_T4mJtFxTiy"}},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SoepdyUiB_F9","executionInfo":{"status":"ok","timestamp":1670573104911,"user_tz":360,"elapsed":947,"user":{"displayName":"Benjamin Elias","userId":"16861639607150618076"}},"outputId":"df5c6ca1-545d-421a-833f-7e745448445a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","\n","drive.mount('/content/gdrive')"]},{"cell_type":"markdown","source":["Install mediapipe for Runtime Analysis"],"metadata":{"id":"s418JYSpxtbk"}},{"cell_type":"code","source":["!pip install mediapipe"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2pcS3C4fhZFZ","executionInfo":{"status":"ok","timestamp":1670573117064,"user_tz":360,"elapsed":8707,"user":{"displayName":"Benjamin Elias","userId":"16861639607150618076"}},"outputId":"2acc1d02-6f00-41e0-d618-d5401efe0616"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting mediapipe\n","  Downloading mediapipe-0.9.0.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (33.0 MB)\n","\u001b[K     |████████████████████████████████| 33.0 MB 150 kB/s \n","\u001b[?25hCollecting flatbuffers>=2.0\n","  Downloading flatbuffers-22.12.6-py2.py3-none-any.whl (26 kB)\n","Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.8/dist-packages (from mediapipe) (22.1.0)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from mediapipe) (3.2.2)\n","Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.8/dist-packages (from mediapipe) (4.6.0.66)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from mediapipe) (1.21.6)\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.8/dist-packages (from mediapipe) (1.3.0)\n","Requirement already satisfied: protobuf<4,>=3.11 in /usr/local/lib/python3.8/dist-packages (from mediapipe) (3.19.6)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->mediapipe) (3.0.9)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->mediapipe) (1.4.4)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->mediapipe) (0.11.0)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->mediapipe) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.1->matplotlib->mediapipe) (1.15.0)\n","Installing collected packages: flatbuffers, mediapipe\n","  Attempting uninstall: flatbuffers\n","    Found existing installation: flatbuffers 1.12\n","    Uninstalling flatbuffers-1.12:\n","      Successfully uninstalled flatbuffers-1.12\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tensorflow 2.9.2 requires flatbuffers<2,>=1.12, but you have flatbuffers 22.12.6 which is incompatible.\u001b[0m\n","Successfully installed flatbuffers-22.12.6 mediapipe-0.9.0.1\n"]}]},{"cell_type":"markdown","source":["CPU Execution Time - Cropped Video"],"metadata":{"id":"ICEb2ce1yzLw"}},{"cell_type":"code","source":["import time\n","st=time.process_time()\n","\n","from ast import Break\n","import cv2\n","import mediapipe as mp\n","import numpy as np\n","import glob\n","\n","#Face Mesh\n","mp_facemesh = mp.solutions.face_mesh\n","face_mesh = mp_facemesh.FaceMesh()\n","\n","vidcap = cv2.VideoCapture('/content/gdrive/MyDrive/434CourseProj/LRNet-main/demo/input/sample_fakeR.mp4')\n","widthh  = int(vidcap.get(3))  # float `width`\n","heighth = int(vidcap.get(4))  # float `height`\n","\n","frameSize = (widthh, heighth)\n","\n","vidout = cv2.VideoWriter('/content/gdrive/MyDrive/434CourseProj/analysis/sample_fakeRLand.mp4',cv2.VideoWriter_fourcc(*'DIVX'),25,frameSize)\n","\n","while True:\n","    success,image = vidcap.read()\n","    if success is not True:\n","      break\n","    #image\n","    height, width,_ = image.shape\n","    rgb_image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n","\n","    result = face_mesh.process(rgb_image)\n","\n","    for facial_landmarks in result.multi_face_landmarks:\n","      for i in range(0,468):\n","          pt1 = facial_landmarks.landmark[i]\n","          x= int(pt1.x * width)\n","          y= int(pt1.y * height)\n","\n","          cv2.circle(image, (x,y), 2, (100,100,0), -1)\n","     \n","    vidout.write(image)\n","    cv2.waitKey(1)\n","\n","vidout.release()\n","\n","et = time.process_time()\n","res = et-st\n","print('CPU Execution Time:',res,'seconds')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"klx-eWwdoKmL","executionInfo":{"status":"ok","timestamp":1670573130204,"user_tz":360,"elapsed":5582,"user":{"displayName":"Benjamin Elias","userId":"16861639607150618076"}},"outputId":"ca89e042-acb7-4428-966b-caee0b9b57d6"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["CPU Execution Time: 4.673182866000001 seconds\n"]}]},{"cell_type":"markdown","source":["CPU Execution Time - Original Video"],"metadata":{"id":"4R7tfqbPy4Ns"}},{"cell_type":"code","source":["import time\n","st=time.process_time()\n","\n","from ast import Break\n","import cv2\n","import mediapipe as mp\n","import numpy as np\n","import glob\n","\n","#Face Mesh\n","mp_facemesh = mp.solutions.face_mesh\n","face_mesh = mp_facemesh.FaceMesh()\n","\n","vidcap = cv2.VideoCapture('/content/gdrive/MyDrive/434CourseProj/LRNet-main/demo/input/sample_fake.mp4')\n","widthh  = int(vidcap.get(3))  # float `width`\n","heighth = int(vidcap.get(4))  # float `height`\n","\n","frameSize = (widthh, heighth)\n","\n","vidout = cv2.VideoWriter('/content/gdrive/MyDrive/434CourseProj/analysis/sample_fakeLand.mp4',cv2.VideoWriter_fourcc(*'DIVX'),25,frameSize)\n","\n","while True:\n","    success,image = vidcap.read()\n","    if success is not True:\n","      break\n","    #image\n","    height, width,_ = image.shape\n","    rgb_image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n","\n","    result = face_mesh.process(rgb_image)\n","\n","    for facial_landmarks in result.multi_face_landmarks:\n","      for i in range(0,468):\n","          pt1 = facial_landmarks.landmark[i]\n","          x= int(pt1.x * width)\n","          y= int(pt1.y * height)\n","\n","          cv2.circle(image, (x,y), 2, (100,100,0), -1)\n","     \n","    vidout.write(image)\n","    cv2.waitKey(1)\n","\n","vidout.release()\n","\n","et = time.process_time()\n","res = et-st\n","print('CPU Execution Time:',res,'seconds')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uUIqPsNey9Yu","executionInfo":{"status":"ok","timestamp":1670573153035,"user_tz":360,"elapsed":12743,"user":{"displayName":"Benjamin Elias","userId":"16861639607150618076"}},"outputId":"5f8de85e-d67d-4863-8ed2-248b764f1983"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["CPU Execution Time: 16.768521859999996 seconds\n"]}]}]}