{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "938e509f",
   "metadata": {},
   "source": [
    "# LRNet-Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7606ef",
   "metadata": {},
   "source": [
    "The training and evaluating codes for LRNet (Jupyter Notebook version).\n",
    "\n",
    "Evironment: `PyTorch==1.8.0; cudatoolkit==11.0.221`\n",
    "\n",
    "Created by FrederickSun at *2022-3-20*\n",
    "\n",
    "Last updated at *2022-3-20*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5112ea",
   "metadata": {},
   "source": [
    "## Preamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a05db6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from tqdm.notebook import tqdm, trange\n",
    "from torch import optim\n",
    "from os.path import join\n",
    "from utils.model import *\n",
    "from utils.logger import Logger\n",
    "from utils.metric import *\n",
    "from utils.dataset import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f114a06",
   "metadata": {},
   "source": [
    "Parameters Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af4bb493",
   "metadata": {},
   "outputs": [],
   "source": [
    "if_gpu = True\n",
    "dataset_name = 'DF'\n",
    "dataset_level = 'c23'\n",
    "branch_selection = 'g1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e9b99dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "BLOCK_SIZE = 60\n",
    "BATCH_SIZE = 1024\n",
    "DROPOUT_RATE = 0.5\n",
    "RNN_UNIT = 64\n",
    "EPOCHS_g1 = 400\n",
    "EPOCHS_g2 = 400\n",
    "LEARNING_RATE = 0.005\n",
    "add_weights = './weights/torch/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15def217",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e8d698e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================\n",
      "==        LOG        ==\n",
      "=======================\n",
      "\n",
      "\n",
      "#-------Status--------#\n",
      "Using device:  cuda\n",
      "Dataset name:  DF\n",
      "Dataset compression level:  c23\n",
      "Directory of real samples:  ['./datasets/Origin/c23']\n",
      "Directory of fake samples:  ['./datasets/DF/c23']\n",
      "Directory of model weights:  ./weights/test/\n",
      "Which branch of the LRNet to be trained:  g1\n",
      "#-----Status End------#\n",
      "\n",
      "\n",
      "#-----Parameters------#\n",
      "Block size (frames per sample):  60\n",
      "Batch size:  1024\n",
      "RNN hidden units:  64\n",
      "Training epochs (g1):  400\n",
      "Training epochs (g2):  20\n",
      "Learning rate  0.005\n",
      "#---Parameters End----#\n",
      "\n",
      "\n",
      "=======================\n",
      "==      LOG END      ==\n",
      "=======================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "GPU\n",
    "\"\"\"\n",
    "if if_gpu:\n",
    "    # Optional to uncomment if some bugs occur.\n",
    "    # os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "else:\n",
    "    device = 'cpu'\n",
    "\n",
    "\"\"\"\n",
    "Dataset\n",
    "\"\"\"\n",
    "dataset = Dataset(name=dataset_name, level=dataset_level)\n",
    "\n",
    "\"\"\"\n",
    "Logs\n",
    "\"\"\"\n",
    "logger = Logger()\n",
    "logger.register_status(dataset=dataset,\n",
    "                       device=device,\n",
    "                       add_weights=add_weights,\n",
    "                       branch_selection=branch_selection)\n",
    "logger.register_parameter(block_size=BLOCK_SIZE,\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          rnn_unit=RNN_UNIT,\n",
    "                          epochs_g1=EPOCHS_g1,\n",
    "                          epochs_g2=EPOCHS_g2,\n",
    "                          learning_rate=LEARNING_RATE)\n",
    "logger.print_logs_training()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a31979b",
   "metadata": {},
   "source": [
    "### load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83093dfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 5/800 [00:00<00:18, 43.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from:  ./datasets/Origin/c23/train/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [00:19<00:00, 40.98it/s]\n",
      "  1%|          | 4/797 [00:00<00:25, 31.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from:  ./datasets/DF/c23/train/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 797/797 [00:24<00:00, 32.30it/s]\n",
      "  2%|▎         | 5/200 [00:00<00:04, 42.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from:  ./datasets/Origin/c23/test/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:04<00:00, 42.62it/s]\n",
      "  2%|▏         | 4/200 [00:00<00:05, 32.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from:  ./datasets/DF/c23/test/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:06<00:00, 32.30it/s]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Loading data\n",
    "\"\"\"\n",
    "train_iter_A = None\n",
    "train_iter_B = None\n",
    "test_iter_A = None\n",
    "test_iter_B = None\n",
    "if branch_selection == 'g1':\n",
    "    train_iter_A = dataset.load_data_train_g1(BLOCK_SIZE, BATCH_SIZE)\n",
    "    test_iter_A, test_labels, test_labels_video, test_sv, test_vc = \\\n",
    "        dataset.load_data_test_g1(BLOCK_SIZE, BATCH_SIZE)\n",
    "elif branch_selection == 'g2':\n",
    "    train_iter_B = dataset.load_data_train_g2(BLOCK_SIZE, BATCH_SIZE)\n",
    "    test_iter_B, test_labels, test_labels_video, test_sv, test_vc = \\\n",
    "        dataset.load_data_test_g2(BLOCK_SIZE, BATCH_SIZE)\n",
    "elif branch_selection == 'all':\n",
    "    train_iter_A, train_iter_B = dataset.load_data_train_all(BLOCK_SIZE, BATCH_SIZE)\n",
    "    test_iter_A, test_iter_B, test_labels, test_labels_video, test_sv, test_vc = \\\n",
    "        dataset.load_data_test_all(BLOCK_SIZE, BATCH_SIZE)\n",
    "else:\n",
    "    print(\"Unknown branch selection:\", branch_selection, '. Please check and restart')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ede7960",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07da3d93",
   "metadata": {},
   "source": [
    "Train loop function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "41dc8590",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(model, train_iter, test_iter, optimizer, loss, epochs, device, add_weights_file):\n",
    "    log_training_loss = []\n",
    "    log_training_accuracy = []\n",
    "    log_testing_accuracy = []\n",
    "    best_test_acc = 0.0\n",
    "\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    for epoch in trange(1, epochs + 1):\n",
    "        loss_sum, acc_sum, samples_sum = 0.0, 0.0, 0\n",
    "        for X, y in train_iter:\n",
    "            # Load data to GPU/cpu\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            samples_num = X.shape[0]\n",
    "\n",
    "            # BP\n",
    "            output = model(X)\n",
    "            log_softmax_output = torch.log(output)\n",
    "            l = loss(log_softmax_output, y)\n",
    "            optimizer.zero_grad()\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Generating Log\n",
    "            loss_sum += l.item() * samples_num\n",
    "            acc_sum += calculate_accuracy(output, y) * samples_num\n",
    "            samples_sum += samples_num\n",
    "\n",
    "        test_acc = evaluate(model, test_iter, device)\n",
    "        if test_acc >= best_test_acc:\n",
    "            save_hint = \"save the model to {}\".format(add_weights_file)\n",
    "            torch.save(model.state_dict(), add_weights_file)\n",
    "            best_test_acc = test_acc\n",
    "        else:\n",
    "            save_hint = \" \"*60\n",
    "        \n",
    "        tqdm.write(\"\\repoch:{}, loss:{:.4}, train_acc:{:.4}, test_acc:{:.4}, best_record:{:.4}  \"\n",
    "                   .format(epoch, loss_sum/samples_sum, acc_sum/samples_sum, test_acc, best_test_acc)\n",
    "                   + save_hint, end='')\n",
    "\n",
    "        log_training_loss.append(loss_sum/samples_sum)\n",
    "        log_training_accuracy.append(acc_sum/samples_sum)\n",
    "        log_testing_accuracy.append(test_acc)\n",
    "\n",
    "    log = {\"loss\": log_training_loss, \"acc_train\": log_training_accuracy, \"acc_test\": log_testing_accuracy}\n",
    "    return log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2aed6c",
   "metadata": {},
   "source": [
    "### g1-training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d28c4fc7",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b086dc4610b49aaaabc4834fc8fc4e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:400, loss:0.2863, train_acc:0.8843, test_acc:0.9013, best_record:0.9079                                                              \n",
      "The model weights are saved at:  ./weights/test/g1.pth\n"
     ]
    }
   ],
   "source": [
    "if branch_selection == 'g1' or branch_selection == 'all':\n",
    "    assert train_iter_A, test_iter_A is not None\n",
    "    g1 = LRNet(RNN_UNIT, DROPOUT_RATE)\n",
    "    optimizer = optim.Adam(g1.parameters(), lr=LEARNING_RATE)\n",
    "    loss = nn.NLLLoss()\n",
    "    add_weights_file = join(add_weights, 'g1.pth')\n",
    "    log_g1 = train_loop(g1, train_iter_A, test_iter_A, optimizer, loss, EPOCHS_g1, device, add_weights_file)\n",
    "    print(\"\\nThe model weights are saved at: \", add_weights_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "29af5cf8",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LRNet(\n",
      "  (dropout_landmark): LandmarkDropout()\n",
      "  (gru): GRU(136, 64, batch_first=True, bidirectional=True)\n",
      "  (dropout_feature_1): Dropout(p=0.5, inplace=False)\n",
      "  (linear_1): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (dropout_feature_2): Dropout(p=0.5, inplace=False)\n",
      "  (linear_2): Linear(in_features=64, out_features=2, bias=True)\n",
      "  (output): Softmax(dim=1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(g1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f6e685",
   "metadata": {},
   "source": [
    "### g2-training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7323c098",
   "metadata": {},
   "outputs": [],
   "source": [
    "if branch_selection == 'g2' or branch_selection == 'all':\n",
    "    assert train_iter_B, test_iter_B is not None\n",
    "    g2 = LRNet(RNN_UNIT, DROPOUT_RATE)\n",
    "    optimizer = optim.Adam(g2.parameters(), lr=LEARNING_RATE)\n",
    "    loss = nn.NLLLoss()\n",
    "    add_weights_file = join(add_weights, 'g2.pth')\n",
    "    log_g2 = train_loop(g2, train_iter_B, test_iter_B, optimizer, loss, EPOCHS_g2, device, add_weights_file)\n",
    "    print(\"\\nThe model weights are saved at: \", add_weights_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4b452b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(g2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e330d95",
   "metadata": {},
   "source": [
    "# LRNet-Evaluating"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62eadb55",
   "metadata": {},
   "source": [
    "## Preamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ddf5501",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from tqdm.notebook import tqdm, trange\n",
    "from torch import optim\n",
    "from os.path import join\n",
    "from utils.model import *\n",
    "from utils.logger import Logger\n",
    "from utils.metric import *\n",
    "from utils.dataset import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870c89d9",
   "metadata": {},
   "source": [
    "Parameters Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69066983",
   "metadata": {},
   "outputs": [],
   "source": [
    "if_gpu = True\n",
    "dataset_name = 'DF'\n",
    "dataset_level = 'c23'\n",
    "branch_selection = 'g1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d536029d",
   "metadata": {},
   "outputs": [],
   "source": [
    "BLOCK_SIZE = 60\n",
    "BATCH_SIZE = 1024\n",
    "DROPOUT_RATE = 0.5\n",
    "RNN_UNIT = 64\n",
    "add_weights = './weights/test/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a8a38e",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60c6741b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================\n",
      "==        LOG        ==\n",
      "=======================\n",
      "\n",
      "\n",
      "#-------Status--------#\n",
      "Using device:  cuda\n",
      "Dataset name:  DF\n",
      "Dataset compression level:  c23\n",
      "Directory of real samples:  ['./datasets/Origin/c23']\n",
      "Directory of fake samples:  ['./datasets/DF/c23']\n",
      "Directory of model weights:  ./weights/test/\n",
      "Which branch of the LRNet to be evaluated:  g1\n",
      "#-----Status End------#\n",
      "\n",
      "\n",
      "=======================\n",
      "==      LOG END      ==\n",
      "=======================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "GPU\n",
    "\"\"\"\n",
    "if if_gpu:\n",
    "    # Optional to uncomment if some bugs occur.\n",
    "    # os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "else:\n",
    "    device = 'cpu'\n",
    "\n",
    "\"\"\"\n",
    "Dataset\n",
    "\"\"\"\n",
    "dataset = Dataset(name=dataset_name, level=dataset_level)\n",
    "\n",
    "\"\"\"\n",
    "Logs\n",
    "\"\"\"\n",
    "logger = Logger()\n",
    "logger.register_status(dataset=dataset,\n",
    "                       device=device,\n",
    "                       add_weights=add_weights,\n",
    "                       branch_selection=branch_selection)\n",
    "logger.print_logs_evaluating()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ddc6ee8",
   "metadata": {},
   "source": [
    "### load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dbf4cfa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▎         | 5/200 [00:00<00:04, 43.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from:  ./datasets/Origin/c23/test/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:04<00:00, 43.31it/s]\n",
      "  2%|▏         | 3/200 [00:00<00:07, 25.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from:  ./datasets/DF/c23/test/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:04<00:00, 42.95it/s]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Loading data\n",
    "\"\"\"\n",
    "test_iter_A = None\n",
    "test_iter_B = None\n",
    "if branch_selection == 'g1':\n",
    "    test_iter_A, test_labels, test_labels_video, test_sv, test_vc = \\\n",
    "        dataset.load_data_test_g1(BLOCK_SIZE, BATCH_SIZE)\n",
    "elif branch_selection == 'g2':\n",
    "    test_iter_B, test_labels, test_labels_video, test_sv, test_vc = \\\n",
    "        dataset.load_data_test_g2(BLOCK_SIZE, BATCH_SIZE)\n",
    "elif branch_selection == 'all':\n",
    "    test_iter_A, test_iter_B, test_labels, test_labels_video, test_sv, test_vc = \\\n",
    "        dataset.load_data_test_all(BLOCK_SIZE, BATCH_SIZE)\n",
    "else:\n",
    "    print(\"Unknown branch selection:\", branch_selection, '. Please check and restart')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29acd177",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b385cd8e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "#----Evaluation  Results----#\n",
      "Evaluation (g1) - Acc: 0.9079\n",
      "Accuracy (video-level):  0.9575\n",
      "#------------End------------#\n"
     ]
    }
   ],
   "source": [
    "g1 = None\n",
    "g2 = None\n",
    "acc_g1 = None\n",
    "acc_g2 = None\n",
    "if branch_selection == 'g1' or branch_selection == 'all':\n",
    "    g1 = LRNet(RNN_UNIT, DROPOUT_RATE)\n",
    "    g1.load_state_dict(torch.load(join(add_weights, 'g1.pth')))\n",
    "    acc_g1 = evaluate(g1, test_iter_A, device)\n",
    "\n",
    "if branch_selection == 'g2' or branch_selection == 'all':\n",
    "    g2 = LRNet(RNN_UNIT, DROPOUT_RATE)\n",
    "    g2.load_state_dict(torch.load(join(add_weights, 'g2.pth')))\n",
    "    acc_g2 = evaluate(g2, test_iter_B, device)\n",
    "\n",
    "\"\"\"\n",
    "Evaluate the [g1+g2] merged prediction (sample-level and video-level).\n",
    "If only evaluating the single branch, the sample-level evaluation \n",
    "    will be SKIPPED because it's equal to acc_g1 or acc_g2.\n",
    "Also, at this situation, the 'mix_predict' will be \n",
    "    directly equal to prediction or prediction_diff.\n",
    "\"\"\"\n",
    "# ----Sample-level----#\n",
    "count_s = None\n",
    "total_s = None\n",
    "if branch_selection == 'g1':\n",
    "    prediction = predict(g1, test_iter_A, device)\n",
    "    mix_predict = list(prediction[:, 1])\n",
    "elif branch_selection == 'g2':\n",
    "    prediction_diff = predict(g2, test_iter_B, device)\n",
    "    mix_predict = list(prediction_diff[:, 1])\n",
    "else:\n",
    "    prediction = predict(g1, test_iter_A, device)\n",
    "    prediction_diff = predict(g2, test_iter_B, device)\n",
    "    count_s = 0\n",
    "    total_s = test_labels.shape[0]\n",
    "    mix_predict = []\n",
    "    for i in range(len(prediction)):\n",
    "        mix = prediction[i][1] + prediction_diff[i][1]\n",
    "        if mix >= 1:\n",
    "            result = 1\n",
    "        else:\n",
    "            result = 0\n",
    "        if result == test_labels[i]:\n",
    "            count_s += 1\n",
    "        mix_predict.append(mix / 2)\n",
    "\n",
    "# ----Video-level----#\n",
    "prediction_video = merge_video_prediction(mix_predict, test_sv, test_vc)\n",
    "count_v = 0\n",
    "total_v = len(test_labels_video)\n",
    "for i, pd in enumerate(prediction_video):\n",
    "    if pd >= 0.5:\n",
    "        result = 1\n",
    "    else:\n",
    "        result = 0\n",
    "    if result == test_labels_video[i]:\n",
    "        count_v += 1\n",
    "\n",
    "\"\"\"\n",
    "Exhibit the evaluation results.\n",
    "\"\"\"\n",
    "print(\"\\n\")\n",
    "print(\"#----Evaluation  Results----#\")\n",
    "if branch_selection == 'g1' or branch_selection == 'all':\n",
    "    print(\"Evaluation (g1) - Acc: {:.4}\".format(acc_g1))\n",
    "if branch_selection == 'g2' or branch_selection == 'all':\n",
    "    print(\"Evaluation (g2) - Acc: {:.4}\".format(acc_g2))\n",
    "if branch_selection == 'all':\n",
    "    print(\"Accuracy (sample-level): \", count_s / total_s)\n",
    "print(\"Accuracy (video-level): \", count_v / total_v)\n",
    "print(\"#------------End------------#\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:lrnet] *",
   "language": "python",
   "name": "conda-env-lrnet-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "191.594px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}